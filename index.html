<html class="gr__filebox_ece_vt_edu"><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

	<style>
	body {
		background:white;
		color: #222222;
		padding: 0;
		margin: 0;
		font-family: "Helvetica Neue", "Helvetica", Helvetica, Arial, sans-serif;
		font-weight: normal;
		font-style: normal;
		line-height: 1.4;
   }
	a:link {
		text-decoration: none;
	}
	a:visited {
		text-decoration: none;
	}
	a:hover {
		text-decoration: underline;
	}
	a:active {
		text-decoration: underline;
	}
	p{
		font-size:1.2em;
	}
	img {
		width:100%;
		max-width: 300px;
	}
	.rcorner{
		border-radius: 25px;
		border: 2px solid #8AC007;
		padding: 20px;
	}
	div{
		max-width:1200px;
		position:relative;
		font-family:Arial;
	}
	.bold{font-weight: bold;}
	.italic{font-style: italic;}
	.sz25{font-size:2.5em;}
	.sz20{font-size:2.0em;}
	.sz15{font-size:1.5em;}
	.sz13{font-size:1.3em;}
	.sz12{font-size:1.2em;}
	.sz10{font-size:1.0em;}
	.sz08{font-size:0.8em;}
	.inline{display:inline-block;}
	.no_margin{
		margin: 0 0;
	}
	.padding20{
		padding: 20px;
	}
	.halign{
		margin-left: auto;
		margin-right: auto;
	}
	.block_2
	{
		width:49%;
		max-width: 512px;
		display: inline-block;
		position: relative;
	}
	.block_5_2
	{
		width:40%;
		max-width: 410px;
		display: inline-block;
		position: relative;
	}
	.block_3
	{
		width:33%;
		max_width: 341px;
		display: inline-block;
		position: relative;
	}
	.block_1
	{
		width:100%;
		display: inline-block;
		/*position: relative;*/
		margin: 5px 5px;
		text-align: justify;

	}
	.block_N
	{
		display: inline-block;
		position: relative;
	}
	.block_6
	{
		width:16%;
		display: inline-block;
		position: relative;

	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 0px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}

	.block_6_5
	{
		width:83%;
		display: inline-block;
		position: relative;
	}
	</style>
	<title>
		SpectFormer: Attention is NOT what matters in a transformer Network
	</title>


</head>
<body data-gr-c-s-loaded="true">

<div class="halign">
	<div style="float: left; width: 15%; padding: 1%;"><a target="_blank" href="https://www.bath.ac.uk/"><img src="https://badripatro.github.io/SpectFormers/images/bath.jpg" height="100" width= "150" alt="sherlock"/></a></div>
	<div style="float: left; width: 65%;">
	<div class="block_1">

		<div class="block_1">
			<p class="sz20 bold no_margin" align="center">SpectFormer: Frequency and Attention is what you need in a Vision Transformer</p>
			<p align="center">
			</p><p class="no_margin" align="center"> <a href="https://badripatro.github.io/">Badri N. Patro</a>, <a href="https://vinaypn.github.io/">Vinay P. Namboodiri</a>, <a href="https://in.linkedin.com/in/vijaysrinivasagneeswaran">Vijay Srinivas Agneeswaran</a></p>
           		 <p  class="no_margin" align="center"><a href="http://microsoft.com/">Microsoft</a>, <a href="http://iitk.ac.in/">University of Bath</a></p>
				<p class="sz12 bold" align="center"></a> <a href="https://arxiv.org/abs/2304.06446">[ArXiv]</a> <a href="https://github.com/badripatro/SpectFormers"> [Code]</a> 

			<p align="center">
			</p>
		</div>
	</div>
</div>
<div style="float: left; width: 15%; padding: 1%;"><a target="_blank" href="http://microsoft.com/"><img src="https://badripatro.github.io/SpectFormers/images/microsoft.png" height="90" width= "150" alt="sherlock"/></a></div>


	<div class="block_1">
		<div class="">
			<p class="sz15 bold">Abstract</p>
				<div class="padding20" style="float:right ">
					<img style="max-width:601px" src="https://badripatro.github.io/SpectFormers/images/SpectFormer.png">
                              
				</div>
				<p class="sz12">
				Vision transformers have been applied successfully for image recognition tasks. There have been either multi-headed self-attention based (ViT \cite{dosovitskiy2020image}, DeIT, \cite{touvron2021training}) similar to the original work in textual models or more recently based on spectral layers (Fnet\cite{lee2021fnet}, GFNet\cite{rao2021global}, AFNO\cite{guibas2021efficient}). We hypothesize that both spectral and multi-headed attention plays a major role. We investigate this hypothesis through this work and observe that indeed combining spectral and multi-headed attention layers provides a better transformer architecture. We thus propose the novel Spectformer architecture for transformers that combines spectral and multi-headed attention layers. We believe that the resulting representation allows the transformer to capture the feature representation appropriately and it yields improved performance over other transformer representations. For instance, it improves the top-1 accuracy by 2\% on ImageNet compared to both GFNet-H and LiT. SpectFormer-S reaches 84.25\% top-1 accuracy on ImageNet-1K (state of the art for small version). Further, Spectformer-L achieves 85.7\% that is the state of the art for the comparable base version of the transformers. We further ensure that we obtain reasonable results in other scenarios such as transfer learning on standard datasets such as CIFAR-10, CIFAR-100, Oxford-IIIT-flower, and Standford Car datasets.  We then investigate its use in downstream tasks such of object detection and instance segmentation on MS-COCO dataset and observe that Spectformer shows consistent performance that is comparable to the best backbones and can be further optimized and improved. Hence, we believe that combined spectral and attention layers are what are needed for vision transformers.
				</p>
			 		
		</div>
	</div>


	<div class="block_1" id="code">
			<div class="">
				<p class="sz15 bold">SpectFormer Main Diagram</p>
			</div>
			<div style="text-align: center;">
           
                    <img style="max-width:75%;" src="https://badripatro.github.io/SpectFormers/images/SpectFormer_main.png">
           
            </div>
	</div>

		<div class="block_1" id="Results1">
			<div class="">
				<p class="sz15 bold">SpectForer Performance Plots  </p>
			</div>
			<div style="text-align: center;">           
             	<img style="max-width:75%;" src="https://badripatro.github.io/SpectFormers/images/gflops.png">
		<img style="max-width:75%;" src="https://badripatro.github.io/SpectFormers/images/params.png">          

            </div>
	</div>
	
	<div class="block_1" id="Results2">
			<div class="">
				<p class="sz15 bold">Results on the ImageNet1K dataset for image size 224 x 224 </p>
			</div>
			<div style="text-align: center;">           
             	<img style="max-width:75%;" src="https://badripatro.github.io/SpectFormers/images/result_sota.png">
            </div>
	</div>
	
<div class="block_1" id="code">
			<div class="">
				<p class="sz15 bold">Filter Visualization</p>
			</div>
			<div style="text-align: center;">
           
             	<img style="max-width:75%;" src="https://badripatro.github.io/SpectFormers/images/GFNet_filter.jpg">
		<img style="max-width:75%;" src="https://badripatro.github.io/SpectFormers/images/SpectFormer_filter.jpg">          

            </div>
	</div>


	<div class="block_1" id="Results2">
		<div class="">
			<p class="sz15 bold">Inference Results</p>
		</div>
			<div style="text-align: center;">           
             	<img style="max-width:75%;" src="https://badripatro.github.io/SpectFormers/images/inference.png">
            </div>
	</div>

<div class="block_1" id="code">
			<div class="">
				<p class="sz15 bold">Paper</p>
			</div>
			
          	<center> 
          	 <table width="700px">
          	 <tbody align="center"><tr>
				  <td><a target="_blank" href="https://arxiv.org/pdf/2304.06446"><img class="layered-paper-big" style="height:150px" src="https://badripatro.github.io/SpectFormers/images/page_1.png"></a></td>
				  <td><span style="font-size:12pt; margin-left: 30px;">Badri N. Patro, Vinay. P. Namboodiri and Vijay Srinivas Agneeswaran<br>
				  <b><span style="font-size:12pt; margin-left: 40px;">SpectFormer: Frequency and Attention is what you need in a Vision Transformer</span></b><br>
				  </span>
				  </td>
  	              
              </tr>
  		  </tbody>
  		  </table>	
          </center>
          
	</div>



	<div class="block_1" id="Bibtex">
			<div class="">
							<p class="sz15 bold">BibTex</p>
							<p style="font-family: Comic Sans MS; font-size: 14px;">@article{patro2023spectformer,<br>
							author = {Patro, Badri N.  and Namboodiri, Vinay P. and Agneeswaran, Vijay Srinivas},<br>
							title = {SpectFormer: Frequency and Attention is what you need in a Vision Transformer},<br>
							journal={arXiv preprint arXiv:2304.06446},<br>
						        year = {2023}<br>
							}<br>
						    </p>
			</div>
	</div>


</div>

<!-- Start Google analytic code  -->	
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-142979632-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-142979632-1');
</script>
<!-- End Google analytic code  -->	
	

<h2></h2>
<p><font color="blue"> *There are no ordinary moments - Dan Millman.</font><br>
</p>

<script type="text/javascript">

</script>

</body></html>
